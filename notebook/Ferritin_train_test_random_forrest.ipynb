{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as mt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of this cell has been removed, as it contained data with sensitive patient information\n",
    "\n",
    "columns = [\"Geslacht\", \"Leeftijd\", \"HB\", \"ERY\", \"MCV\", \"MCH\", \"TRMB\", \"LEU\", \"CRP\", \"FER\", \"VITB12\", \"FOL\"]\n",
    "replace_dict = {\"Geslacht\": {'M': 1, \"V\": 0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some initial data visualization\n",
    "\n",
    "plt.scatter(man_df['HB'], man_df['VITB12'])\n",
    "plt.title(\"VITB12\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(man_df['HB'], man_df['FER'])\n",
    "plt.title(\"FER\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(man_df['HB'], man_df['FOL'])\n",
    "plt.title(\"FOL\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(man_nofol_df[:-3].isnull().values.any())\n",
    "print(man_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up data, streamline column names and check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_man = pd.concat([man_df[columns], man_df_2019[columns], man_df_2020[columns], \n",
    "                    man_df_2019_2[columns], man_nofol_df[columns]])\n",
    "df_woman = pd.concat([woman_df[columns], woman_df_2019[columns], woman_df_2020[columns], woman_nofol_df[columns],\n",
    "                      woman_df_2019_2[columns]])\n",
    "\n",
    "columns = [\"Geslacht\", \"Leeftijd\", \"HB\", \"ERY\", \"MCV\", \"MCH\", \"TRMB\", \"LEU\", \"CRP\", \"FER\"]\n",
    "for df in [df_man, df_vrouw]:\n",
    "    df.replace(replace_dict, inplace=True)\n",
    "\n",
    "    df['Leeftijd'] = df['Leeftijd'].astype(np.float64)\n",
    "    df['MCV']= df['MCV'].astype(np.float64)\n",
    "    df['TRMB'] = df['TRMB'].astype(np.float64)\n",
    "    df['CRP'] = df['CRP'].astype(np.float64)\n",
    "\n",
    "    # no NANs\n",
    "    for c in columns:\n",
    "        print(c)\n",
    "        print(df[c].isnull().values.any())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split up in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chec\n",
    "\n",
    "print(len(df_man) - np.sum(df_man['VITB12'].notna()))\n",
    "print(len(df_man) - np.sum(df_man['FOL'].notna()))\n",
    "print(len(df_man) - np.sum(df_man['FER'].notna()))\n",
    "\n",
    "print(len(df_vrouw) - np.sum(df_vrouw['VITB12'].notna()))\n",
    "print(len(df_vrouw) - np.sum(df_vrouw['FOL'].notna()))\n",
    "print(len(df_man) - np.sum(df_man['FER'].notna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_name = \"FER\"\n",
    "Xnp_man = df_man\n",
    "ynp_man = pd.cut(df_man[\"FER\"], bins=[-float(\"inf\"),30,float(\"inf\")],labels=[1,0]).to_numpy()\n",
    "# ynp = np.log10(df[\"FER\"].to_numpy())\n",
    "\n",
    "# ynp = pd.cut(df[\"VITB12\"], bins=[-float(\"inf\"),200,float(\"inf\")],labels=[0,1]).to_numpy()\n",
    "# ynp = pd.cut(df[\"FOL\"], bins=[-float(\"inf\"),6,39,float(\"inf\")],labels=[0,1,0], ordered=False).to_numpy()\n",
    "Xnp_vrouw = df_vrouw\n",
    "ynp_vrouw = pd.cut(df_vrouw[\"FER\"], bins=[-float(\"inf\"),13,float(\"inf\")],labels=[1,0]).to_numpy()\n",
    "\n",
    "Xnp = pd.concat([Xnp_man,Xnp_vrouw])\n",
    "ynp = np.concatenate([ynp_man, ynp_vrouw])\n",
    "\n",
    "X_train, X_test, ynp_train, ynp_test = train_test_split(Xnp, ynp, test_size=0.3, random_state=42)\n",
    "Xnp_train = X_train[columns[0:-3]].to_numpy()\n",
    "Xnp_test = X_test[columns[0:-3]].to_numpy()\n",
    "ynpCopy_train = ynp_train.copy()\n",
    "XnpCopy_train = Xnp_train.copy()\n",
    "print(Xnp_man.shape)\n",
    "print(Xnp_vrouw.shape)\n",
    "print(Xnp_train.shape)\n",
    "print(ynp_train.shape)\n",
    "print(Xnp_test.shape)\n",
    "print(ynp_test.shape)\n",
    "print(len(Xnp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "regr = RandomForestClassifier(random_state=40, class_weight=\"balanced_subsample\")\n",
    "regr.fit(Xnp_train, ynp_train)\n",
    "importances = regr.feature_importances_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "filename = 'random_forest_model_ferritine.sav'\n",
    "pickle.dump(regr, open(filename, 'wb'))\n",
    "clf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "\n",
    "importances = regr.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in regr.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(indices)\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for ind, f in enumerate(indices):\n",
    "    print(\"{}. feature {} ({})\".format(ind+1, columns[:-1][f], importances[indices[ind]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(Xnp_train.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(Xnp_train.shape[1]), np.asarray(columns[:])[indices])\n",
    "plt.xlim([-1, Xnp_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a few output\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"predicted: {}\".format(regr.predict(Xnp_test[i].reshape(1, -1))))\n",
    "    print(\"proba: {}\".format(regr.predict_proba(Xnp_test[i].reshape(1, -1))))\n",
    "    print(\"actual: {}\".format(ynp_test[i]))\n",
    "\n",
    "\n",
    "y_pred = regr.predict(Xnp_test)\n",
    "y_proba = regr.predict_proba(Xnp_test)\n",
    "print(\"score: {}\".format(regr.score(Xnp_test, ynp_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p_test_pos = y_proba[:,1]\n",
    "y_roc = np.copy(ynp_test)\n",
    "\n",
    "print(\"Area under ROC curve \", mt.roc_auc_score(y_score=p_test_pos, y_true=y_roc))\n",
    "fpr, tpr, tresh = mt.roc_curve(y_roc, p_test_pos, pos_label=1)\n",
    "plt.title(\"ROC predict low {}\".format(predict_name))\n",
    "plt.xlim(-0.005,1.0)\n",
    "plt.ylim(0.0,1.005)\n",
    "plt.plot(fpr, tpr)\n",
    "# plt.savefig(\"FER_Roc_nofol.png\", format=\"png\")\n",
    "\n",
    "# disp = plot_precision_recall_curve(regr, Xnp_test, ynp_test)\n",
    "# disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "#                    'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FER: Check optimal cutoffs for ferritin levels\n",
    "\n",
    "predict_name = \"FER\"\n",
    "men_cutoff = [18,19,20,21,22,23,24,25,26]\n",
    "women_cutoff = [6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "for man_cutoff in men_cutoff:\n",
    "    for woman_cutoff in women_cutoff:\n",
    "        Xnp_man = df_man\n",
    "        ynp_man = pd.cut(df_man[\"FER\"], bins=[-float(\"inf\"),man_cutoff,float(\"inf\")],labels=[1,0]).to_numpy()\n",
    "        Xnp_vrouw = df_vrouw\n",
    "        ynp_vrouw = pd.cut(df_vrouw[\"FER\"], bins=[-float(\"inf\"),woman_cutoff,float(\"inf\")],labels=[1,0]).to_numpy()\n",
    "        Xnp = pd.concat([Xnp_man,Xnp_vrouw])\n",
    "        ynp = np.concatenate([ynp_man, ynp_vrouw])\n",
    "        X_train, X_test, ynp_train, ynp_test = train_test_split(Xnp, ynp, test_size=0.2, random_state=42)\n",
    "        Xnp_train = X_train[columns[0:-3]].to_numpy()\n",
    "        Xnp_test = X_test[columns[0:-3]].to_numpy()\n",
    "        \n",
    "        regr = RandomForestClassifier(random_state=42, class_weight=\"balanced_subsample\")\n",
    "        regr.fit(Xnp_train, ynp_train)\n",
    "        y_proba = regr.predict_proba(Xnp_test)\n",
    "        \n",
    "        p_test_pos = y_proba[:,1]\n",
    "        # p_test_pos = (y_proba + 1) / 2 #ridge\n",
    "        y_roc = np.copy(ynp_test)\n",
    "        print(\"{} {} {}\".format(woman_cutoff, man_cutoff, mt.roc_auc_score(y_score=p_test_pos, y_true=y_roc)))\n",
    "#         print(\"women: {}, men: {}, AUC: {}\".format(woman_cutoff, man_cutoff, mt.roc_auc_score(y_score=p_test_pos, y_true=y_roc)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we can check our model on independent validation data and write output to excel sheet\n",
    "\n",
    "X_test['FER']\n",
    "X_test['model_output'] = y_proba[:,1]\n",
    "X_test.replace({\"Geslacht\": {1: 'M', 0: \"V\"}}, inplace=True)\n",
    "with pd.ExcelWriter(r\"REMOVED\") as writer:  \n",
    "    X_test.to_excel(writer, sheet_name='Validation_data', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
